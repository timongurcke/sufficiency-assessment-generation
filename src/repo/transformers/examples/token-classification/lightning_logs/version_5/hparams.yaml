accumulate_grad_batches: 1
adafactor: false
adam_epsilon: 1.0e-08
attention_dropout: null
cache_dir: ''
config_name: ''
data_dir: /workspace/ceph_data/intermediate/bert-AAE-v2-iob/0
decoder_layerdrop: null
do_predict: true
do_train: true
dropout: null
encoder_layerdrop: null
eval_batch_size: 32
fp16: false
fp16_opt_level: O2
gpus: 1
gradient_clip_val: 1.0
labels: /workspace/ceph_data/intermediate/bert-AAE-v2-iob/0/labels.txt
learning_rate: 5.0e-05
lr_scheduler: linear
max_epochs: 10
max_seq_length: 512
model_name_or_path: bert-base-cased
num_workers: 4
output_dir: /workspace/ceph_data/output/bert-AAE-v2-iob/0
overwrite_cache: false
seed: 1
task_type: NER
tokenizer_name: null
tpu_cores: null
train_batch_size: 4
warmup_steps: 0
weight_decay: 0.0
